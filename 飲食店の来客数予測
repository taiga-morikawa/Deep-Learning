import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV

# CSV読み込み
air_reserve = pd.read_csv("air_reserve.csv")
air_store_info = pd.read_csv("air_store_info.csv")
air_visit_data = pd.read_csv("air_visit_data.csv")
date_info = pd.read_csv("date_info.csv")
hpg_reserve = pd.read_csv("hpg_reserve.csv")
hpg_store_info = pd.read_csv("hpg_store_info.csv")
store_id_relation = pd.read_csv("store_id_relation.csv")

# 全てのCSVを一気に読み込む（ご参考）
#import glob
#dfs = { fn[2:-4]:pd.read_csv(fn) for fn in glob.glob('./*.csv')}
#for k, v in dfs.items(): locals()[k] = v

# airレジ店舗の数
len(air_store_info["air_store_id"])

829

# ホットペッパー利用店舗の数
len(store_id_relation["air_store_id"])

150

# airレジを使っている店舗の客数情報
air_visit_data["visit_date"] =  pd.to_datetime(air_visit_data['visit_date'])
air_visit_data.set_index('visit_date', inplace=True)  # 横軸を時間表示するためにインデックス化
air_visit_data.head()

air_store_id	visitors
visit_date		
2016-01-13	air_ba937bf13d40fb24	25
2016-01-14	air_ba937bf13d40fb24	32
2016-01-15	air_ba937bf13d40fb24	29
2016-01-16	air_ba937bf13d40fb24	22
2016-01-18	air_ba937bf13d40fb24	6

# あるレストランのサンプル数チェック
store_id_column = air_visit_data["air_store_id"]
store_id = store_id_column[0]
df_sub = air_visit_data[store_id_column == store_id] # air_ba937bf13d40fb24のお店
len(df_sub)

391

# あるレストランの客数推移プロット
df_sub.plot()
plt.show()

# レストラン10店舗の来客数推移プロット
for i, store_id in enumerate(np.unique(store_id_column)):
    if i == 10:
        break
    
    air_visit_data[store_id_column == store_id].plot()
    plt.title(store_id)
    plt.show()
    
    # 後の処理のためインデックスを戻しておく
air_visit_data.reset_index(inplace=True)
air_visit_data.head()

	visit_date	air_store_id	visitors
0	2016-01-13	air_ba937bf13d40fb24	25
1	2016-01-14	air_ba937bf13d40fb24	32
2	2016-01-15	air_ba937bf13d40fb24	29
3	2016-01-16	air_ba937bf13d40fb24	22
4	2016-01-18	air_ba937bf13d40fb24	6

# airレジを使っている店舗の情報
air_store_info.head()

air_store_id	air_genre_name	air_area_name	latitude	longitude
0	air_0f0cdeee6c9bf3d7	Italian/French	Hyōgo-ken Kōbe-shi Kumoidōri	34.695124	135.197852
1	air_7cc17a324ae5c7dc	Italian/French	Hyōgo-ken Kōbe-shi Kumoidōri	34.695124	135.197852
2	air_fee8dcf4d619598e	Italian/French	Hyōgo-ken Kōbe-shi Kumoidōri	34.695124	135.197852
3	air_a17f0778617c76e2	Italian/French	Hyōgo-ken Kōbe-shi Kumoidōri	34.695124	135.197852
4	air_83db5aff8f50478e	Italian/French	Tōkyō-to Minato-ku Shibakōen	35.658068	139.751599

# 緯度経度は今回は不使用
air_store_info.drop(["latitude", "longitude"], axis=1, inplace=True)
air_store_info.head()

	air_store_id	air_genre_name	air_area_name
0	air_0f0cdeee6c9bf3d7	Italian/French	Hyōgo-ken Kōbe-shi Kumoidōri
1	air_7cc17a324ae5c7dc	Italian/French	Hyōgo-ken Kōbe-shi Kumoidōri
2	air_fee8dcf4d619598e	Italian/French	Hyōgo-ken Kōbe-shi Kumoidōri
3	air_a17f0778617c76e2	Italian/French	Hyōgo-ken Kōbe-shi Kumoidōri
4	air_83db5aff8f50478e	Italian/French	Tōkyō-to Minato-ku Shibakōen

# 練習でイメージを掴むため、例としてある店舗での学習データを作成（後ほど全店舗でforループを回す）
store_id_column = air_visit_data["air_store_id"] # 先ほどreset_indexをしたため、再度列を取り出す
store_id = store_id_column[0]
df_store = air_visit_data[store_id_column == store_id].sort_values("visit_date") # 既に日付順のはずだが念のためソート
df_store

	visit_date	air_store_id	visitors
0	2016-01-13	air_ba937bf13d40fb24	25
1	2016-01-14	air_ba937bf13d40fb24	32
2	2016-01-15	air_ba937bf13d40fb24	29
3	2016-01-16	air_ba937bf13d40fb24	22
4	2016-01-18	air_ba937bf13d40fb24	6
...	...	...	...
386	2017-04-18	air_ba937bf13d40fb24	11
387	2017-04-19	air_ba937bf13d40fb24	11
388	2017-04-20	air_ba937bf13d40fb24	14
389	2017-04-21	air_ba937bf13d40fb24	40
390	2017-04-22	air_ba937bf13d40fb24	23

# 日付欠損を埋めてから線形補間するための前準備として、まず抜けの無い日付連番を用意
df_dates = pd.DataFrame({
    "visit_date": pd.date_range(
        np.min(df_store["visit_date"]),
        periods=(np.max(df_store["visit_date"]) - np.min(df_store["visit_date"])).days,
        freq='D')
})
df_dates

	visit_date
0	2016-01-13
1	2016-01-14
2	2016-01-15
3	2016-01-16
4	2016-01-17
...	...
460	2017-04-17
461	2017-04-18
462	2017-04-19
463	2017-04-20
464	2017-04-21

# 日付連番データと来客数データを結合し、日付欠損行を挿入
df_store = pd.merge(df_dates, df_store, how="left")
df_store

	visit_date	air_store_id	visitors
0	2016-01-13	air_ba937bf13d40fb24	25.0
1	2016-01-14	air_ba937bf13d40fb24	32.0
2	2016-01-15	air_ba937bf13d40fb24	29.0
3	2016-01-16	air_ba937bf13d40fb24	22.0
4	2016-01-17	NaN	NaN
...	...	...	...
460	2017-04-17	air_ba937bf13d40fb24	10.0
461	2017-04-18	air_ba937bf13d40fb24	11.0
462	2017-04-19	air_ba937bf13d40fb24	11.0
463	2017-04-20	air_ba937bf13d40fb24	14.0
464	2017-04-21	air_ba937bf13d40fb24	40.0

# 来客数欠損を線形補間
df_store.interpolate(inplace=True)
df_store

	visit_date	air_store_id	visitors
0	2016-01-13	air_ba937bf13d40fb24	25.0
1	2016-01-14	air_ba937bf13d40fb24	32.0
2	2016-01-15	air_ba937bf13d40fb24	29.0
3	2016-01-16	air_ba937bf13d40fb24	22.0
4	2016-01-17	NaN	14.0
...	...	...	...
460	2017-04-17	air_ba937bf13d40fb24	10.0
461	2017-04-18	air_ba937bf13d40fb24	11.0
462	2017-04-19	air_ba937bf13d40fb24	11.0
463	2017-04-20	air_ba937bf13d40fb24	14.0
464	2017-04-21	air_ba937bf13d40fb24	40.0

# 店舗ID欠損を補間
df_store["air_store_id"].fillna(store_id, inplace=True)
df_store

	visit_date	air_store_id	visitors
0	2016-01-13	air_ba937bf13d40fb24	25.0
1	2016-01-14	air_ba937bf13d40fb24	32.0
2	2016-01-15	air_ba937bf13d40fb24	29.0
3	2016-01-16	air_ba937bf13d40fb24	22.0
4	2016-01-17	air_ba937bf13d40fb24	14.0
...	...	...	...
460	2017-04-17	air_ba937bf13d40fb24	10.0
461	2017-04-18	air_ba937bf13d40fb24	11.0
462	2017-04-19	air_ba937bf13d40fb24	11.0
463	2017-04-20	air_ba937bf13d40fb24	14.0
464	2017-04-21	air_ba937bf13d40fb24	40.0

# 目的変数は翌日の客数
df_store["y"] = df_store["visitors"].shift(-1)
df_store

	visit_date	air_store_id	visitors	y
0	2016-01-13	air_ba937bf13d40fb24	25.0	32.0
1	2016-01-14	air_ba937bf13d40fb24	32.0	29.0
2	2016-01-15	air_ba937bf13d40fb24	29.0	22.0
3	2016-01-16	air_ba937bf13d40fb24	22.0	14.0
4	2016-01-17	air_ba937bf13d40fb24	14.0	6.0
...	...	...	...	...
460	2017-04-17	air_ba937bf13d40fb24	10.0	11.0
461	2017-04-18	air_ba937bf13d40fb24	11.0	11.0
462	2017-04-19	air_ba937bf13d40fb24	11.0	14.0
463	2017-04-20	air_ba937bf13d40fb24	14.0	40.0
464	2017-04-21	air_ba937bf13d40fb24	40.0	NaN

# 過去1週間の客数を説明変数に追加
for j in range(1, 8):
    df_store["prev" + str(j)] = df_store["visitors"].shift(j)  # n日前の客数
    
df_store

	visit_date	air_store_id	visitors	y	prev1	prev2	prev3	prev4	prev5	prev6	prev7
0	2016-01-13	air_ba937bf13d40fb24	25.0	32.0	NaN	NaN	NaN	NaN	NaN	NaN	NaN
1	2016-01-14	air_ba937bf13d40fb24	32.0	29.0	25.0	NaN	NaN	NaN	NaN	NaN	NaN
2	2016-01-15	air_ba937bf13d40fb24	29.0	22.0	32.0	25.0	NaN	NaN	NaN	NaN	NaN
3	2016-01-16	air_ba937bf13d40fb24	22.0	14.0	29.0	32.0	25.0	NaN	NaN	NaN	NaN
4	2016-01-17	air_ba937bf13d40fb24	14.0	6.0	22.0	29.0	32.0	25.0	NaN	NaN	NaN
...	...	...	...	...	...	...	...	...	...	...	...
460	2017-04-17	air_ba937bf13d40fb24	10.0	11.0	1.0	16.0	27.0	17.0	7.0	9.0	3.0
461	2017-04-18	air_ba937bf13d40fb24	11.0	11.0	10.0	1.0	16.0	27.0	17.0	7.0	9.0
462	2017-04-19	air_ba937bf13d40fb24	11.0	14.0	11.0	10.0	1.0	16.0	27.0	17.0	7.0
463	2017-04-20	air_ba937bf13d40fb24	14.0	40.0	11.0	11.0	10.0	1.0	16.0	27.0	17.0
464	2017-04-21	air_ba937bf13d40fb24	40.0	NaN	14.0	11.0	11.0	10.0	1.0	16.0	27.0

# y～prev7までに欠損が含まれる行を削除
df_store.dropna(inplace=True)
df_store

	visit_date	air_store_id	visitors	y	prev1	prev2	prev3	prev4	prev5	prev6	prev7
7	2016-01-20	air_ba937bf13d40fb24	31.0	21.0	9.0	6.0	14.0	22.0	29.0	32.0	25.0
8	2016-01-21	air_ba937bf13d40fb24	21.0	18.0	31.0	9.0	6.0	14.0	22.0	29.0	32.0
9	2016-01-22	air_ba937bf13d40fb24	18.0	26.0	21.0	31.0	9.0	6.0	14.0	22.0	29.0
10	2016-01-23	air_ba937bf13d40fb24	26.0	23.5	18.0	21.0	31.0	9.0	6.0	14.0	22.0
11	2016-01-24	air_ba937bf13d40fb24	23.5	21.0	26.0	18.0	21.0	31.0	9.0	6.0	14.0
...	...	...	...	...	...	...	...	...	...	...	...
459	2017-04-16	air_ba937bf13d40fb24	1.0	10.0	16.0	27.0	17.0	7.0	9.0	3.0	14.0
460	2017-04-17	air_ba937bf13d40fb24	10.0	11.0	1.0	16.0	27.0	17.0	7.0	9.0	3.0
461	2017-04-18	air_ba937bf13d40fb24	11.0	11.0	10.0	1.0	16.0	27.0	17.0	7.0	9.0
462	2017-04-19	air_ba937bf13d40fb24	11.0	14.0	11.0	10.0	1.0	16.0	27.0	17.0	7.0
463	2017-04-20	air_ba937bf13d40fb24	14.0	40.0	11.0	11.0	10.0	1.0	16.0	27.0	17.0

# テスト用データは最後の日とする
df_store["is_test"] = 0
df_store.loc[np.max(df_store.index), "is_test"] = 1
df_store

	visit_date	air_store_id	visitors	y	prev1	prev2	prev3	prev4	prev5	prev6	prev7	is_test
7	2016-01-20	air_ba937bf13d40fb24	31.0	21.0	9.0	6.0	14.0	22.0	29.0	32.0	25.0	0
8	2016-01-21	air_ba937bf13d40fb24	21.0	18.0	31.0	9.0	6.0	14.0	22.0	29.0	32.0	0
9	2016-01-22	air_ba937bf13d40fb24	18.0	26.0	21.0	31.0	9.0	6.0	14.0	22.0	29.0	0
10	2016-01-23	air_ba937bf13d40fb24	26.0	23.5	18.0	21.0	31.0	9.0	6.0	14.0	22.0	0
11	2016-01-24	air_ba937bf13d40fb24	23.5	21.0	26.0	18.0	21.0	31.0	9.0	6.0	14.0	0
...	...	...	...	...	...	...	...	...	...	...	...	...
459	2017-04-16	air_ba937bf13d40fb24	1.0	10.0	16.0	27.0	17.0	7.0	9.0	3.0	14.0	0
460	2017-04-17	air_ba937bf13d40fb24	10.0	11.0	1.0	16.0	27.0	17.0	7.0	9.0	3.0	0
461	2017-04-18	air_ba937bf13d40fb24	11.0	11.0	10.0	1.0	16.0	27.0	17.0	7.0	9.0	0
462	2017-04-19	air_ba937bf13d40fb24	11.0	14.0	11.0	10.0	1.0	16.0	27.0	17.0	7.0	0
463	2017-04-20	air_ba937bf13d40fb24	14.0	40.0	11.0	11.0	10.0	1.0	16.0	27.0	17.0	1

# 各店舗ごとに分けて、時系列情報を加工し、学習・テスト用データの作成準備
matrix = []
store_id_list = np.unique(air_store_info["air_store_id"])
for i, store_id in enumerate(store_id_list):
    if (i+1) % 50 == 0:
        print("%d / %d" % (i+1, len(store_id_list)))
    
    df_store = air_visit_data[store_id_column == store_id].sort_values("visit_date")

    # 日付欠損を埋めてから線形補間するための前準備として、まず抜けの無い日付連番を用意
    df_dates = pd.DataFrame({
        "visit_date": pd.date_range(
            np.min(df_store["visit_date"]),
            periods=(np.max(df_store["visit_date"]) - np.min(df_store["visit_date"])).days,
            freq='D')
    })
    
    # 日付連番データと来客数データを結合し、日付欠損行を挿入
    df_store = pd.merge(df_dates, df_store, how="left", on="visit_date")

    # 来客数欠損を線形補間
    df_store.interpolate(inplace=True)

    # 店舗ID欠損を補間
    df_store["air_store_id"].fillna(store_id, inplace=True)

    # 目的変数は翌日の客数
    df_store["y"] = df_store["visitors"].shift(-1)

    # 過去1週間の客数を説明変数に追加
    for j in range(1, 8):
        df_store["prev" + str(j)] = df_store["visitors"].shift(j)  # n日前の客数

    # y～prev7までに欠損が含まれる行を削除
    df_store.dropna(inplace=True)

    # テスト用データは最後の日とする
    df_store["is_test"] = 0
    df_store.loc[np.max(df_store.index), "is_test"] = 1

    # 上記までで加工したある店舗のデータ群をリストに追加
    matrix += list(df_store.values)
    
    # ループの初回で列名を記憶しておく
    if i == 0:
        colnames = df_store.columns

# 全店舗の処理が終了後、蓄積した加工データをpandas型へ変換
matrix = pd.DataFrame(matrix, columns=colnames)
matrix

50 / 829
100 / 829
150 / 829
200 / 829
250 / 829
300 / 829
350 / 829
400 / 829
450 / 829
500 / 829
550 / 829
600 / 829
650 / 829
700 / 829
750 / 829
800 / 829
visit_date	air_store_id	visitors	y	prev1	prev2	prev3	prev4	prev5	prev6	prev7	is_test
0	2016-07-08	air_00a91d42b08b08d9	42.0	11.0	34.0	29.0	25.0	20.0	14.5	9.0	35.0	0
1	2016-07-09	air_00a91d42b08b08d9	11.0	18.0	42.0	34.0	29.0	25.0	20.0	14.5	9.0	0
2	2016-07-10	air_00a91d42b08b08d9	18.0	25.0	11.0	42.0	34.0	29.0	25.0	20.0	14.5	0
3	2016-07-11	air_00a91d42b08b08d9	25.0	24.0	18.0	11.0	42.0	34.0	29.0	25.0	20.0	0
4	2016-07-12	air_00a91d42b08b08d9	24.0	36.0	25.0	18.0	11.0	42.0	34.0	29.0	25.0	0
...	...	...	...	...	...	...	...	...	...	...	...	...
288813	2017-04-16	air_fff68b929994bfbd	7.0	3.0	7.0	5.0	1.0	6.0	1.0	6.0	5.0	0
288814	2017-04-17	air_fff68b929994bfbd	3.0	6.0	7.0	7.0	5.0	1.0	6.0	1.0	6.0	0
288815	2017-04-18	air_fff68b929994bfbd	6.0	2.0	3.0	7.0	7.0	5.0	1.0	6.0	1.0	0
288816	2017-04-19	air_fff68b929994bfbd	2.0	2.0	6.0	3.0	7.0	7.0	5.0	1.0	6.0	0
288817	2017-04-20	air_fff68b929994bfbd	2.0	4.0	2.0	6.0	3.0	7.0	7.0	5.0	1.0	1

# 店舗情報の追加
matrix = pd.merge(matrix, air_store_info, how="left", on="air_store_id")

# 曜日と祝日情報の追加
date_info["calendar_date"] = pd.to_datetime(date_info["calendar_date"])
matrix = pd.merge(matrix, date_info, how="left", left_on="visit_date", right_on="calendar_date")

matrix

	visit_date	air_store_id	visitors	y	prev1	prev2	prev3	prev4	prev5	prev6	prev7	is_test	air_genre_name	air_area_name	calendar_date	day_of_week	holiday_flg
0	2016-07-08	air_00a91d42b08b08d9	42.0	11.0	34.0	29.0	25.0	20.0	14.5	9.0	35.0	0	Italian/French	Tōkyō-to Chiyoda-ku Kudanminami	2016-07-08	Friday	0
1	2016-07-09	air_00a91d42b08b08d9	11.0	18.0	42.0	34.0	29.0	25.0	20.0	14.5	9.0	0	Italian/French	Tōkyō-to Chiyoda-ku Kudanminami	2016-07-09	Saturday	0
2	2016-07-10	air_00a91d42b08b08d9	18.0	25.0	11.0	42.0	34.0	29.0	25.0	20.0	14.5	0	Italian/French	Tōkyō-to Chiyoda-ku Kudanminami	2016-07-10	Sunday	0
3	2016-07-11	air_00a91d42b08b08d9	25.0	24.0	18.0	11.0	42.0	34.0	29.0	25.0	20.0	0	Italian/French	Tōkyō-to Chiyoda-ku Kudanminami	2016-07-11	Monday	0
4	2016-07-12	air_00a91d42b08b08d9	24.0	36.0	25.0	18.0	11.0	42.0	34.0	29.0	25.0	0	Italian/French	Tōkyō-to Chiyoda-ku Kudanminami	2016-07-12	Tuesday	0
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
288813	2017-04-16	air_fff68b929994bfbd	7.0	3.0	7.0	5.0	1.0	6.0	1.0	6.0	5.0	0	Bar/Cocktail	Tōkyō-to Nakano-ku Nakano	2017-04-16	Sunday	0
288814	2017-04-17	air_fff68b929994bfbd	3.0	6.0	7.0	7.0	5.0	1.0	6.0	1.0	6.0	0	Bar/Cocktail	Tōkyō-to Nakano-ku Nakano	2017-04-17	Monday	0
288815	2017-04-18	air_fff68b929994bfbd	6.0	2.0	3.0	7.0	7.0	5.0	1.0	6.0	1.0	0	Bar/Cocktail	Tōkyō-to Nakano-ku Nakano	2017-04-18	Tuesday	0
288816	2017-04-19	air_fff68b929994bfbd	2.0	2.0	6.0	3.0	7.0	7.0	5.0	1.0	6.0	0	Bar/Cocktail	Tōkyō-to Nakano-ku Nakano	2017-04-19	Wednesday	0
288817	2017-04-20	air_fff68b929994bfbd	2.0	4.0	2.0	6.0	3.0	7.0	7.0	5.0	1.0	1	Bar/Cocktail	Tōkyō-to Nakano-ku Nakano	2017-04-20	Thursday	0

# 質的変数のダミー化
matrix_dummy = pd.get_dummies(matrix, drop_first=True, columns=["air_genre_name", "air_area_name", "day_of_week"])
matrix_dummy

	visit_date	air_store_id	visitors	y	prev1	prev2	prev3	prev4	prev5	prev6	...	air_area_name_Ōsaka-fu Ōsaka-shi Nanbasennichimae	air_area_name_Ōsaka-fu Ōsaka-shi Shinmachi	air_area_name_Ōsaka-fu Ōsaka-shi Ōgimachi	air_area_name_Ōsaka-fu Ōsaka-shi Ōhiraki	day_of_week_Monday	day_of_week_Saturday	day_of_week_Sunday	day_of_week_Thursday	day_of_week_Tuesday	day_of_week_Wednesday
0	2016-07-08	air_00a91d42b08b08d9	42.0	11.0	34.0	29.0	25.0	20.0	14.5	9.0	...	0	0	0	0	0	0	0	0	0	0
1	2016-07-09	air_00a91d42b08b08d9	11.0	18.0	42.0	34.0	29.0	25.0	20.0	14.5	...	0	0	0	0	0	1	0	0	0	0
2	2016-07-10	air_00a91d42b08b08d9	18.0	25.0	11.0	42.0	34.0	29.0	25.0	20.0	...	0	0	0	0	0	0	1	0	0	0
3	2016-07-11	air_00a91d42b08b08d9	25.0	24.0	18.0	11.0	42.0	34.0	29.0	25.0	...	0	0	0	0	1	0	0	0	0	0
4	2016-07-12	air_00a91d42b08b08d9	24.0	36.0	25.0	18.0	11.0	42.0	34.0	29.0	...	0	0	0	0	0	0	0	0	1	0
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
288813	2017-04-16	air_fff68b929994bfbd	7.0	3.0	7.0	5.0	1.0	6.0	1.0	6.0	...	0	0	0	0	0	0	1	0	0	0
288814	2017-04-17	air_fff68b929994bfbd	3.0	6.0	7.0	7.0	5.0	1.0	6.0	1.0	...	0	0	0	0	1	0	0	0	0	0
288815	2017-04-18	air_fff68b929994bfbd	6.0	2.0	3.0	7.0	7.0	5.0	1.0	6.0	...	0	0	0	0	0	0	0	0	1	0
288816	2017-04-19	air_fff68b929994bfbd	2.0	2.0	6.0	3.0	7.0	7.0	5.0	1.0	...	0	0	0	0	0	0	0	0	0	1
288817	2017-04-20	air_fff68b929994bfbd	2.0	4.0	2.0	6.0	3.0	7.0	7.0	5.0	...	0	0	0	0	0	0	0	1	0	0

# 学習・テストデータの分割
X_train_valid = matrix_dummy[matrix_dummy["is_test"] == 0].drop(["y", "air_store_id", "visit_date", "calendar_date", "is_test"], axis=1)
y_train_valid = matrix_dummy[matrix_dummy["is_test"] == 0]["y"]
X_test = matrix_dummy[matrix_dummy["is_test"] == 1].drop(["y", "air_store_id", "visit_date", "calendar_date", "is_test"], axis=1)
y_test = matrix_dummy[matrix_dummy["is_test"] == 1]["y"]

params = {
    "max_depth": [2, 4, 6, 8, None],
    "n_estimators": [50,100,200],
    "max_features": range(1, 11),
    "min_samples_split": range(2, 11),
    "min_samples_leaf": range(1, 11)
}

kfold = KFold(n_splits=2, shuffle=False)  # 時系列順序を考慮して、分割数2＆ランダムシャッフルなし
rscv = RandomizedSearchCV(RandomForestRegressor(), params, cv=kfold, n_iter=30, n_jobs=-1, verbose=1)
rscv.fit(X_train_valid, y_train_valid)
            
print("Best score: {}".format(rscv.best_score_))
print("Best parameters: {}".format(rscv.best_params_))

Fitting 2 folds for each of 30 candidates, totalling 60 fits
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.
[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   46.6s
[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.9min finished
Best score: 0.537487160003964
Best parameters: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 9, 'max_depth': None}

rscv.score(X_train_valid, y_train_valid)

0.7291162944755198

# 正解と予測のプロット
plt.figure(figsize=[10, 10])
y_pred = rscv.predict(X_train_valid)
axis_range = [0, np.max([np.max(y_train_valid), np.max(y_pred)])*1.1]
plt.xlim(axis_range)  # 横軸の範囲
plt.ylim(axis_range)  # 縦軸の範囲
plt.xlabel("True Values", fontsize=20)  # 横軸のラベルと文字の大きさ
plt.ylabel("Predicted Values", fontsize=20)  # 縦軸のラベルと文字の大きさ
plt.xticks(fontsize=14)  # 横軸目盛の文字の大きさ
plt.yticks(fontsize=14)  # 縦軸目盛の文字の大きさ
plt.plot(axis_range, axis_range, color="red", zorder=-1)  # 斜めの基準線を引く（線が背後になるようにz軸順序は-1とする）
plt.scatter(
    y_train_valid,
    y_pred
)
plt.show()

# 斜め45度線に不自然に載っているものを抽出
X_train_valid[y_pred > 200]

	visitors	prev1	prev2	prev3	prev4	prev5	prev6	prev7	holiday_flg	air_genre_name_Bar/Cocktail	...	air_area_name_Ōsaka-fu Ōsaka-shi Nanbasennichimae	air_area_name_Ōsaka-fu Ōsaka-shi Shinmachi	air_area_name_Ōsaka-fu Ōsaka-shi Ōgimachi	air_area_name_Ōsaka-fu Ōsaka-shi Ōhiraki	day_of_week_Monday	day_of_week_Saturday	day_of_week_Sunday	day_of_week_Thursday	day_of_week_Tuesday	day_of_week_Wednesday
256953	211.276316	206.684211	202.092105	197.500000	192.907895	188.315789	183.723684	179.131579	0	0	...	0	0	0	0	0	0	0	0	0	1
256954	215.868421	211.276316	206.684211	202.092105	197.500000	192.907895	188.315789	183.723684	0	0	...	0	0	0	0	0	0	0	1	0	0
256955	220.460526	215.868421	211.276316	206.684211	202.092105	197.500000	192.907895	188.315789	0	0	...	0	0	0	0	0	0	0	0	0	0
256956	225.052632	220.460526	215.868421	211.276316	206.684211	202.092105	197.500000	192.907895	0	0	...	0	0	0	0	0	1	0	0	0	0
256957	229.644737	225.052632	220.460526	215.868421	211.276316	206.684211	202.092105	197.500000	0	0	...	0	0	0	0	0	0	1	0	0	0
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
257033	205.064516	208.774194	212.483871	216.193548	219.903226	223.612903	227.322581	231.032258	0	0	...	0	0	0	0	0	1	0	0	0	0
257034	201.354839	205.064516	208.774194	212.483871	216.193548	219.903226	223.612903	227.322581	0	0	...	0	0	0	0	0	0	1	0	0	0
257035	197.645161	201.354839	205.064516	208.774194	212.483871	216.193548	219.903226	223.612903	0	0	...	0	0	0	0	1	0	0	0	0	0
257036	193.935484	197.645161	201.354839	205.064516	208.774194	212.483871	216.193548	219.903226	0	0	...	0	0	0	0	0	0	0	0	1	0
257037	190.225806	193.935484	197.645161	201.354839	205.064516	208.774194	212.483871	216.193548	0	0	...	0	0	0	0	0	0	0	0	0	1

rscv.score(X_test, y_test)

0.6793477066252847

# 正解と予測のプロット
plt.figure(figsize=[10, 10])
y_pred = rscv.predict(X_test)
axis_range = [0, np.max([np.max(y_test), np.max(y_pred)])*1.1]
plt.xlim(axis_range)  # 横軸の範囲
plt.ylim(axis_range)  # 縦軸の範囲
plt.xlabel("True Values", fontsize=20)  # 横軸のラベルと文字の大きさ
plt.ylabel("Predicted Values", fontsize=20)  # 縦軸のラベルと文字の大きさ
plt.xticks(fontsize=14)  # 横軸目盛の文字の大きさ
plt.yticks(fontsize=14)  # 縦軸目盛の文字の大きさ
plt.plot(axis_range, axis_range, color="red", zorder=-1)  # 斜めの基準線を引く（線が背後になるようにz軸順序は-1とする）
plt.scatter(
    y_test,
    y_pred
)
plt.show()




